# 意图分类模型优缺点对比

## 1. 正则模型

### 优点
- **速度快**：直接字符串匹配，毫秒级响应
- **资源消耗低**：无需加载大型模型，内存占用极小
- **规则明确**：分类逻辑透明，易于理解和调试
- **无需训练**：配置规则即可使用，开发成本低
- **稳定性高**：不受数据分布影响，结果可预测

### 缺点
- **准确率低**：仅基于关键词匹配，无法理解语义
- **维护成本高**：需要人工编写和维护大量规则
- **泛化能力差**：无法处理同义词、近义词等变体
- **覆盖不全**：新场景需要不断添加规则
- **无法处理复杂语义**：对上下文理解能力弱

---

## 2. TF-IDF + SVM 模型

### 优点
- **速度较快**：传统机器学习方法，推理速度快
- **准确率中等**：基于统计特征，比规则方法效果好
- **资源占用适中**：模型文件小，内存占用低
- **训练简单**：使用 scikit-learn，训练流程标准化
- **可解释性较好**：可通过特征权重分析分类原因

### 缺点
- **特征表达能力有限**：TF-IDF 无法捕获深层语义
- **需要大量标注数据**：训练效果依赖数据质量
- **对同义词不敏感**：词袋模型忽略词序和语义关系
- **准确率上限较低**：难以达到深度学习模型的性能
- **特征工程依赖**：需要分词、停用词等预处理

---

## 3. BERT

### 优点
- **准确率高**：基于 Transformer 架构，语义理解能力强
- **上下文感知**：能够理解词序和上下文关系
- **泛化能力强**：预训练模型迁移学习效果好
- **处理复杂语义**：可识别同义词、近义词、多义词
- **端到端学习**：无需复杂的特征工程

### 缺点
- **推理速度慢**：需要 GPU 加速，CPU 推理耗时（100-500ms）
- **资源消耗大**：模型文件大（几百MB），显存占用高
- **训练成本高**：需要 GPU 和较长训练时间
- **部署复杂**：需要配置 CUDA 环境
- **可解释性差**：黑盒模型，难以分析分类原因

---

## 4. 大语言模型

### 优点
- **灵活性强**：无需训练，通过提示词即可使用
- **准确率高**：大模型语义理解能力强
- **适应新场景快**：修改提示词即可适配新任务
- **Few-shot 学习**：通过示例快速适应新类别
- **可处理复杂任务**：支持多轮对话、推理等

### 缺点
- **依赖外部服务**：需要 LLM API，存在网络延迟
- **成本高**：API 调用费用，大规模使用成本高
- **速度慢**：网络请求 + 模型推理，耗时最长（500ms-2s）
- **可能产生幻觉**：模型可能输出不在类别列表中的结果
- **稳定性依赖服务**：受 API 服务可用性影响
- **提示词工程复杂**：需要精心设计提示词模板
