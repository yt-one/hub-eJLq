为实现用户提问与历史 FAQ 的高精度语义匹配，采用 Sentence-BERT（SBERT） 作为核心文本编码模型，并结合向量检索技术完成相似度计算。

## 技术方案

1. 模型选型：选用中文优化的预训练 SBERT 模型。

2. 离线向量构建
- 遍历所有 FAQ，收集标准问法及其有效相似问法；
- 对每个问题文本独立调用 SBERT 编码器，生成向量；
- 将所有向量存入高效向量索引库，并绑定对应的 faq_id

3. 在线匹配流程
- 用户提问时，实时使用同一 SBERT 模型将问题编码为向量；
- 在向量库中执行近似最近邻搜索（ANN），返回 Top-1 最相似的 faq_id；
- 后端根据 faq_id 查询数据库，返回对应渠道视角下的答案。

4. 优势说明

- 相比原始 BERT 需成对输入计算相似度（复杂度 O(n²)），SBERT 支持单句独立编码，仅需 O(n) 次推理即可构建全量索引，线上匹配延迟低，适合实时性高客服场景

## 流程图

```text
用户提问
    ↓
[Tokenize + SBERT 编码]
    ↓
生成问题向量
    ↓
[向量库检索 问题向量]
    ↓
返回最相似 faq_id
    ↓
[查询数据库获取答案]
    ↓
返回对应视角的答案给用户
```
