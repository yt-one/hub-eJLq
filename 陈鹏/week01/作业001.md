1、配置好python环境，包括常见的jieba、sklearn、pytorch等

见  图片1.png

2、使用 dataset.csv数据集完成文本分类操作，需要尝试2种不同的模型。

```
# 导入pandas库，并简写为pd（Python数据分析领域的行业惯例）
# 核心作用：用于数据的读取、清洗、处理和分析
# 本项目用途：加载csv格式的文本分类数据集，统计各类别的样本数量
import pandas as pd

# 导入jieba库（中文分词工具）
# 核心作用：将连续的中文字符串切分成独立的词语（中文没有天然的单词分隔符）
# 本项目用途：对中文文本进行分词处理，为后续的文本特征提取做准备
import jieba

# 从sklearn的特征提取模块导入CountVectorizer类
# 核心作用：将文本数据转换为词频矩阵（Bag of Words词袋模型）
# 本项目用途：把分词后的文本转换成机器学习模型能识别的数值型特征（统计每个词语出现的次数）
from sklearn.feature_extraction.text import CountVectorizer

# 从sklearn的近邻算法模块导入KNeighborsClassifier类（KNN分类器）
# 核心作用：实现K近邻分类算法，基于样本间的相似度进行分类
# 本项目用途：作为文本分类的机器学习模型，用词频特征训练并预测文本类别
from sklearn.neighbors import KNeighborsClassifier

# 从openai库导入OpenAI客户端类
# 核心作用：提供调用OpenAI兼容接口的大语言模型的能力
# 本项目用途：调用阿里云通义千问（qwen-flash）模型，实现基于大语言模型的文本分类
from openai import OpenAI

# 使用pandas的read_csv函数读取数据集文件
# 参数说明：
#   "dataset.csv"：数据集文件路径
#   sep="\t"：文件中的数据用制表符分隔（不是逗号）
#   header=None：文件没有列名（表头）
#   nrows=10000：只读取前10000行数据（避免数据量太大处理慢）
dataset = pd.read_csv("dataset.csv", sep="\t", header=None, nrows=10000)
# 统计数据集中第1列（类别列）的各类别样本数量，方便查看数据分布
print(dataset[1].value_counts())

# sklearn对中文处理
input_sententce = dataset[0].apply(lambda x: " ".join(jieba.lcut(x)))

# 对文本进行提取特征 默认是使用标点符号分词， 不是模型
vector = CountVectorizer()
# 统计词表
vector.fit(input_sententce.values)
# 进行转换 100 * 词表大小
input_feature = vector.transform(input_sententce.values)

# 创建KNN分类器对象，使用默认参数（n_neighbors=5，即取最近的5个邻居投票）
model = KNeighborsClassifier()
# 用训练数据训练模型
model.fit(input_feature, dataset[1].values)

client = OpenAI(
    # 若没有配置环境变量，请用百炼API Key将下行替换为：api_key="sk-xxx",
    # https://bailian.console.aliyun.com/?tab=model#/api-key
    api_key="sk-fe0209453f0d48179de8bd53a6ce028c",  # 账号绑定，用来计费的

    # 大模型厂商的地址，阿里云
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
)

def text_classify_using_ml(text: str) -> str:
    """
    文本分类（机器学习），输入文本完成类别划分
    """
    # 对输入的待分类文本进行分词处理（和训练数据保持一致）
    test_sentence = " ".join(jieba.lcut(text))
    # 对分词后的文本进行转换
    test_feature = vector.transform([test_sentence])
    return model.predict(test_feature)[0]

def text_classify_using_llm(text: str) -> str:
    """
    文本分类（大语言模型），输入文本完成类别划分
    """
    completion = client.chat.completions.create(
        model="qwen-flash",  # 模型的代号

        messages=[
            {"role": "user", "content": f"""帮我进行文本分类：{text}
输出的类别只能从如下中进行选择， 除了类别之外下列的类别，请给出最合适的类别。
FilmTele-Play            
Video-Play               
Music-Play              
Radio-Listen           
Alarm-Update        
Travel-Query        
HomeAppliance-Control  
Weather-Query          
Calendar-Query      
TVProgram-Play      
Audio-Play       
Other             
"""},  # 用户的提问
        ]
    )
    return completion.choices[0].message.content


def text_classify_using_dp(text: str) -> str:
    """
    文本分类（大语言模型），输入文本完成类别划分
    """
    completion = client.chat.completions.create(
        model="deepseek-v3.2",  # DeepSeek通用对话模型（核心参数）
        messages=[
            {"role": "system", "content": "你是一个精准的文本分类助手，只输出指定类别，不输出任何解释或多余文字。"},
            {"role": "user", "content": f"""帮我进行文本分类：{text}
    输出的类别只能从如下列表中选择一个：
    FilmTele-Play、Video-Play、Music-Play、Radio-Listen、Alarm-Update、Travel-Query、HomeAppliance-Control、Weather-Query、Calendar-Query、TVProgram-Play、Audio-Play、Other
    """},
        ]
    )
    # 获取并清洗输出结果
    return completion.choices[0].message.content.strip()


if __name__ == "__main__":
    print("2222")
    # pandas 用来进行表格的加载和分析
    # numpy 从矩阵的角度进行加载和计算
    print("机器学习: ", text_classify_using_ml("帮我导航到天安门"))
    print("大语言模型: ", text_classify_using_llm("帮我导航到天安门"))
    print("大语言模型2: ", text_classify_using_dp("帮我导航到循礼门"))
    print("---------------")
    print("机器学习: ", text_classify_using_ml("设置早上7点的闹钟"))
    print("大语言模型: ", text_classify_using_llm("设置早上7点的闹钟"))
    print("大语言模型2: ", text_classify_using_dp("设置早上7点的闹钟"))

```

运行结果

```
D:\AI\miniconda3\envs\py312\python.exe "D:\AI\PyCharm 2024.1.3\1-my\study\Week01\13_文本分类.py" 
D:\AI\miniconda3\envs\py312\Lib\site-packages\jieba\_compat.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
Building prefix dict from the default dictionary ...
Loading model from cache C:\Users\chenpeng\AppData\Local\Temp\jieba.cache
1
FilmTele-Play            1095
Video-Play               1095
Music-Play               1094
Radio-Listen             1092
Alarm-Update             1082
Travel-Query             1072
HomeAppliance-Control    1070
Weather-Query            1070
Calendar-Query           1055
TVProgram-Play            110
Audio-Play                105
Other                      60
Name: count, dtype: int64
Loading model cost 0.826 seconds.
Prefix dict has been built successfully.
2222
机器学习:  Travel-Query
大语言模型:  Travel-Query
大语言模型2:  Travel-Query
---------------
机器学习:  Alarm-Update
大语言模型:  Alarm-Update
大语言模型2:  Alarm-Update

Process finished with exit code 0

```

